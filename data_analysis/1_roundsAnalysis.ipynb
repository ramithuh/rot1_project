{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b00e0791-4a0d-4454-9853-73fed1f1b3d8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### import libraries and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7352d83-0a26-4f70-9021-3ac58e380a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import gzip\n",
    "import pandas as pd\n",
    "\n",
    "# only look at rounds files; not ZeroCycle\n",
    "data_dir = \"/n/holyscratch01/wadduwage_lab/ramith/SELEX/SELEX/\"\n",
    "\n",
    "file_names = sorted([x for x in os.listdir(data_dir) if ('.gz' in x and \"ZeroCycle\" not in x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ef63092-9246-4584-b0ef-c0f80c217f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(file_names) == 2069"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "672da76f-8980-4145-9099-d97c14400834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 2069 number of files:\n",
      "ALX3_ESAE_TGCAAG20NGA_1.txt.gz\n",
      "ALX3_ESAE_TGCAAG20NGA_2.txt.gz\n",
      "ALX3_ESAE_TGCAAG20NGA_3.txt.gz\n",
      "ALX3_ESAE_TGCAAG20NGA_4.txt.gz\n",
      "ALX3_ESZ_TGTAAA20NAAG_1.txt.gz\n",
      "ALX3_ESZ_TGTAAA20NAAG_2.txt.gz\n",
      "ALX3_ESZ_TGTAAA20NAAG_3.txt.gz\n",
      "ALX3_ESZ_TGTAAA20NAAG_4.txt.gz\n",
      "ALX4_ESW_TGTGTC20NGA_1.txt.gz\n",
      "ALX4_ESW_TGTGTC20NGA_2.txt.gz\n"
     ]
    }
   ],
   "source": [
    "print(f\"found {len(file_names)} number of files:\")\n",
    "for i in range(0,10):\n",
    "    print(file_names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "def20144-b2ea-4d93-a813-d12786f6dcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_regex_matches(string, round_id, verbose = False):\n",
    "    \"\"\"\n",
    "        We are interested only a particular {round_id} so only retrieve those files from the base dir\n",
    "    \"\"\"\n",
    "    \n",
    "    pattern = rf\"([A-Za-z0-9-]+)_([A-Za-z]+)_([A-Za-z]+)(\\d+N)([A-Z]+)?_{round_id}\\.txt\\.gz\"\n",
    "    matches = re.findall(pattern, string)\n",
    "    \n",
    "    if matches and verbose:\n",
    "        code1, code2, code3, code4, code5, code6 = matches[0]\n",
    "        print(code1)  # Output: Alx1\n",
    "        print(code2)  # Output: ESZ\n",
    "        print(code3)  # Output: TAAAGC\n",
    "        print(code4)  # Output: 20N\n",
    "        print(code5)  # Output: CG\n",
    "\n",
    "    if not(matches):\n",
    "        if(verbose):\n",
    "            print(f\"Regex failed at {string}\")\n",
    "        return None \n",
    "        \n",
    "    return matches[0]\n",
    "    \n",
    "def additional_check(file_name, regex_out):\n",
    "    codes = file_name.split(\"_\")\n",
    "\n",
    "    assert regex_out[0]  == codes[0], f\"{file_name} --> {regex_out[0]}<>{codes[0]}\"\n",
    "    assert regex_out[1]  == codes[1]\n",
    "    #assert regex_out[-1] == codes[-1][:-len('.txt.gz')], f\"{file_name} --> {regex_out[-1]}<>{codes[-1]}\"\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9580ef9-b078-414b-9e7b-4c781f689517",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f56d3a-584c-4604-a17f-07f5398517c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "299556e9-9ef9-4bbc-a54f-916dd09e41c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dictionaries to store \n",
    "\n",
    "rp_dict = { '1' : [], '2' : [], '3' : [], '4' : [], '5' : []} #proteins in each round_id\n",
    "rf_dict = { '1' : [], '2' : [], '3' : [], '4' : [], '5' : []} #file_name in each round_id\n",
    "regex_dict = { '1' : [], '2' : [], '3' : [], '4' : [], '5' : []} #the whole segmented file keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17219aac-c575-4277-9051-022a7f719ec1",
   "metadata": {},
   "source": [
    "### looping through file names to gather some summary of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b70e3cf-4db9-413a-b037-455ecd1dc1c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1\n",
      "['ALX3_ESAE_TGCAAG20NGA_1.txt.gz', 'ALX3_ESZ_TGTAAA20NAAG_1.txt.gz', 'ALX4_ESW_TGTGTC20NGA_1.txt.gz']\n",
      "513\n",
      "ALX3 Zic3\n",
      "441\n",
      "__________\n",
      "Round 2\n",
      "['ALX3_ESAE_TGCAAG20NGA_2.txt.gz', 'ALX3_ESZ_TGTAAA20NAAG_2.txt.gz', 'ALX4_ESW_TGTGTC20NGA_2.txt.gz']\n",
      "516\n",
      "ALX3 Zic3\n",
      "443\n",
      "__________\n",
      "Round 3\n",
      "['ALX3_ESAE_TGCAAG20NGA_3.txt.gz', 'ALX3_ESZ_TGTAAA20NAAG_3.txt.gz', 'ALX4_ESW_TGTGTC20NGA_3.txt.gz']\n",
      "516\n",
      "ALX3 Zic3\n",
      "441\n",
      "__________\n",
      "Round 4\n",
      "['ALX3_ESAE_TGCAAG20NGA_4.txt.gz', 'ALX3_ESZ_TGTAAA20NAAG_4.txt.gz', 'ALX4_ESW_TGTGTC20NGA_4.txt.gz']\n",
      "518\n",
      "ALX3 Zic3\n",
      "444\n",
      "__________\n",
      "Round 5\n",
      "['Foxk1_ESQ_TGGGTA20NCG_5.txt.gz', 'Gbx1_ESQ_TCGGTT20NCG_5.txt.gz', 'Hlf_ESP_TCAATT20NTA_5.txt.gz']\n",
      "6\n",
      "Foxk1 Sox10\n",
      "6\n",
      "__________\n"
     ]
    }
   ],
   "source": [
    "for round_id in range(1,6):\n",
    "    \n",
    "    with open('temp.txt', 'w') as file:\n",
    "        \n",
    "        for string in file_names:\n",
    "            \n",
    "            # get file matches for round_id\n",
    "            matches = get_regex_matches(string, round_id)\n",
    "            \n",
    "            if(matches == None): # not something we are interested in\n",
    "                continue\n",
    "            else:\n",
    "                ## valid match\n",
    "                \n",
    "                rp_dict[str(round_id)].append(matches[0])\n",
    "                rf_dict[str(round_id)].append(string)\n",
    "                regex_dict[str(round_id)].append(matches)\n",
    "                \n",
    "                file.write(str(matches + (round_id,))+'\\n')\n",
    "                \n",
    "                # sanity check\n",
    "                additional_check(string, matches)\n",
    "\n",
    "                \n",
    "    ### Some stats\n",
    "    print(f\"Round {round_id}\")\n",
    "    print(rf_dict[str(round_id)][:3])\n",
    "    print(len(rp_dict[str(round_id)])) #number of proteins in round\n",
    "    \n",
    "    u_protiens = set(rp_dict[str(round_id)]) #number of unique proteins in round\n",
    "    print(sorted(u_protiens)[0], sorted(u_protiens)[-1])\n",
    "    print(len(u_protiens))\n",
    "    print(\"__________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdec01b5-a9f7-45fa-9ca3-634daf61bfaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b965b1f-50ac-496f-8f87-7e79f1142513",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Checks to see if new different proteins appear in subsequent rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16e746ed-1b25-42bf-8446-2bf73e9ed778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(rp_dict['1']) == set(rp_dict['3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecd919e7-d6c9-4bba-92d7-1d498d840e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DRGX', 'E2F1', 'HES5', 'TFEB'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(rp_dict['4']).difference(set(rp_dict['1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe799768-7a1b-4ff7-b4b9-324d184dc655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'E2F1', 'ZSCAN4'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(rp_dict['4']).difference(set(rp_dict['2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a97a30f-e5c7-4c2f-8389-bf9d9f1e1eb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BHLHB2', 'FIGLA', 'SCRT2', 'ZNF232'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(rp_dict['4']).difference(set(rp_dict['3']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ad46ed8-9db3-4376-96ac-9eab06b91903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'E2F1' in rp_dict['2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6127a3a-f38d-4a64-b6c2-1631340f9040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MEF2D'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(rp_dict['1']).difference(set(rp_dict['4']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d87e5641-1b8d-45ea-94cd-a0381076173c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BHLHB2', 'FIGLA', 'SCRT2', 'ZNF232'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(rp_dict['1']).difference(set(rp_dict['3']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4d1186-a2f8-46ea-89c6-e65a9307d0c1",
   "metadata": {},
   "source": [
    "### Read codes.txt to see how many unique proteins are there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00bef208-7dd8-425d-9846-1122b4904700",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('protein_info.csv')\n",
    "all_proteins = set(df['HNGC-name'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8145423-4558-4bbf-9369-c649352d9827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "463"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_proteins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97829d74-4c8c-4b6d-956e-4ec25595cb55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CTCF',\n",
       " 'DRGX',\n",
       " 'E2F1',\n",
       " 'EHF',\n",
       " 'ELF4',\n",
       " 'ELK4',\n",
       " 'ETV2',\n",
       " 'Egr1_E410D_FARSDERtoFARSDDR',\n",
       " 'GLIS1',\n",
       " 'GLIS3',\n",
       " 'HES5',\n",
       " 'MEIS1',\n",
       " 'NFKB2',\n",
       " 'NRL',\n",
       " 'RFX4',\n",
       " 'SNAI2',\n",
       " 'SP1',\n",
       " 'SP3',\n",
       " 'SPIB',\n",
       " 'TFEB',\n",
       " 'TP63',\n",
       " 'Trp53',\n",
       " 'Trp73'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_proteins.difference(set(rp_dict['1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99146b2-9665-4658-abc4-f9f5847150a6",
   "metadata": {},
   "source": [
    "### Reading round files to count number of DNA fragments (read HISEQ2 data to retrieve DNA data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "036ee901-7628-46b5-8ddb-0ba009fff15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_dna(seq):\n",
    "    valid_chars = set('ACGT')\n",
    "    return all(c in valid_chars for c in seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a374ab48-55ec-4c2a-815a-aaa856c75dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of files we have = 518\n",
      "0,10,20,30,40,50,60,70,80,"
     ]
    }
   ],
   "source": [
    "## dictionary in which we will keep our sequence data\n",
    "ambiguous_dna = 0\n",
    "\n",
    "r_idx = 4\n",
    "\n",
    "r_dna_seq_len_dict = {str(r_idx): [] }\n",
    "r_dna_seq_dict     = {str(r_idx): [] }\n",
    "\n",
    "file_names = rf_dict[str(r_idx)] #retrieve file names\n",
    "\n",
    "protein_dna_matched_dict = {}\n",
    "\n",
    "print(f\" Number of files we have = {len(file_names)}\")\n",
    "\n",
    "for idx, file in enumerate(file_names): ## loop through files in round_idx\n",
    "    \n",
    "    if(idx%10==0):\n",
    "        print(idx, end = \",\")\n",
    "        \n",
    "    file_name = file_names[idx]\n",
    "    protein_name = file_name.split(\"_\")[0]\n",
    "    \n",
    "    ## Open file\n",
    "    with gzip.open(data_dir + file_names[idx], 'rt') as f:\n",
    "        \n",
    "        assert protein_name == regex_dict[str(r_idx)][idx][0] #make sure that the protein name matches\n",
    "        \n",
    "        \n",
    "        if(protein_name not in protein_dna_matched_dict.keys()): ## we haven't made an entry in the dictionary yet\n",
    "            protein_dna_matched_dict[protein_name] = []\n",
    "        \n",
    "        for i, line in enumerate(f):\n",
    "            if i % 4 == 1:  # Every fourth line, starting with the second line (index 1)\n",
    "                temp = line.strip()\n",
    "                \n",
    "                r_dna_seq_dict[str(r_idx)].append(temp)\n",
    "                r_dna_seq_len_dict[str(r_idx)].append(len(temp)) ## keep track of lengths\n",
    "                \n",
    "                is_valid = is_valid_dna(temp)\n",
    "                \n",
    "                if(not(is_valid)):\n",
    "                    ambiguous_dna+=1\n",
    "                \n",
    "                ## Add to matched dictionary as well !\n",
    "                protein_dna_matched_dict[protein_name].append((temp,is_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa4a530-db59-45f9-b220-576a3ceacda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ambiguous_dna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a56b74-91d3-432c-98e1-c9c172d52785",
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_dict[str(r_idx)][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc9785a-85d3-45ce-90ae-f55602ad6cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89474f92-efa0-499e-8b43-125f5ab829f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(r_dna_seq_len_dict['4'])==len(r_dna_seq_dict['4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db4d437-c90e-4bee-bcb3-44b85d207bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(r_dna_seq_dict['4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77c6fdd-f2b5-41cb-9124-8b2eb54e7d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e79fe1a-bf34-43af-8b85-5cd84e114529",
   "metadata": {},
   "outputs": [],
   "source": [
    "dna_sequence_lengths = np.array(dna_sequence_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0998ef-b17b-48bd-a835-5dc12a82b72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dna_sequence_lengths.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd48e717-34d9-4588-a70e-0b3ee254d220",
   "metadata": {},
   "outputs": [],
   "source": [
    "dna_sequence_lengths.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ab9d24-6e09-48d6-be37-f8d997f6beeb",
   "metadata": {},
   "source": [
    "### Load Zero Cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe45a40-717e-4a1c-bbce-a5cf6d6b9579",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "file_names = sorted([x for x in os.listdir(data_dir) if ('.gz' in x and \"ZeroCycle\" in x)])\n",
    "\n",
    "file_names[:5], len(file_names)\n",
    "\n",
    "zero_cycle_dna_seq = []\n",
    "issue_pos = []\n",
    "zero_cycle_dna_seq_len = []\n",
    "\n",
    "count = 0\n",
    "\n",
    "for idx, file in enumerate(file_names):\n",
    "    if(idx%10==0):\n",
    "        print(idx, end = \",\")\n",
    "    \n",
    "    with gzip.open(data_dir + file_names[idx], 'rt') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i % 4 == 1:  # Every fourth line, starting with the second line (index 1)\n",
    "                temp = line.strip()\n",
    "                zero_cycle_dna_seq.append(temp)\n",
    "                zero_cycle_dna_seq_len.append(len(temp))\n",
    "\n",
    "\n",
    "                if(not(is_valid_dna(temp))):\n",
    "                    issue_pos.append(count)\n",
    "                count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7829bc80-8dae-4202-9bab-859240e907d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(protein_dna_matched_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805ddc02-b7b7-4f4e-9c1d-73e116ae4c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(zero_cycle_dna_seq) == len(zero_cycle_dna_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5eeb9d-fd59-4b8d-a001-20fa990293d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(zero_cycle_dna_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dbea41-fafc-4b3f-b757-c389f479248a",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 0\n",
    "issue_pos[l], zero_cycle_dna_seq[issue_pos[l]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513ad91b-b35b-45b9-a2dc-882a71324e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_dna_matched_dict[protein_id][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a60c0a-8e46-4b42-902f-8d5b62006310",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_sequence = 'TAAGCTCACAGCAGGGGGTT'\n",
    "\n",
    "exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35baea96-d067-424e-974d-59481fcfa9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "protein_id\n",
    "matches_set = set(item[0] for item in protein_dna_matched_dict[protein_id][:100])\n",
    "len(matches_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eecca13-2604-4cd5-8cbf-e2f918f6fdf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca11fbf-3e04-4bae-94c6-b35d3a081421",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "headers = [\n",
    "    [\"Protein_Name\",\"DNA_Fragment\",\"Label\"],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba480c62-b802-44f0-a846-69827739c7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for protein_id in protein_dna_matched_dict.keys(): #loop through each protein\n",
    "    \n",
    "    with open(f\"{protein_id}_negatives.csv\", 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerows(headers)\n",
    "        \n",
    "        matches_set = set(item[0] for item in protein_dna_matched_dict[protein_id])\n",
    "        \n",
    "        ## loop through zero cycle 300M\n",
    "        for idx, dna_fragment in enumerate(zero_cycle_dna_seq):\n",
    "            \n",
    "            if(idx in issue_pos): #if invalid continue\n",
    "                continue\n",
    "            \n",
    "            # check if fragment is there in round 4, if not it's a negative\n",
    "            if(not(dna_fragment in matches_set)):\n",
    "                writer.writerows([[ protein_id, dna_fragment, 0]])\n",
    "\n",
    "        print(protein_id, len(protein_dna_matched_dict[str(protein_id)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9482cb52-6237-4c00-a84a-80a7bbec6a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd7229f-b364-476b-af6d-4bb7b60169a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax",
   "language": "python",
   "name": "jax"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
